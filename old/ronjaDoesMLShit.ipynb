{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T14:10:22.765729Z",
     "start_time": "2024-06-30T14:10:22.750191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from os import getenv\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "id": "1f154b3811279a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:45:52.485351Z",
     "start_time": "2024-06-30T13:45:51.890210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define database connection parameters\n",
    "username = getenv('DB_USER').lower()\n",
    "password = getenv('DB_PASSWORD')\n",
    "host = getenv('DB_HOST')\n",
    "port = getenv('DB_PORT')\n",
    "database = getenv('DB_NAME')\n",
    "\n",
    "# Define the connection string\n",
    "# Format: dialect+driver://username:password@host:port/database\n",
    "connection_string = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(connection_string)\n",
    "# Import the data to separate dataframes\n",
    "df_main = pd.read_sql(\"SELECT * FROM original_data.super_duper_table_of_doom\", engine)\n",
    "\n",
    "#df_main.dropna(inplace=True)\n",
    "\n",
    "df_main = pd.get_dummies(df_main, columns=['land'])\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "df_main['date'] = pd.to_datetime(df_main['date'])\n",
    "\n",
    "# Create 'year' and 'month' columns\n",
    "df_main['year'] = df_main['date'].dt.year\n",
    "df_main['month'] = df_main['date'].dt.month\n",
    "\n",
    "# Drop nan in the target column\n",
    "df_main.dropna(subset=['uebernachtungen_anzahl'], inplace=True)"
   ],
   "id": "562658a69b9503ff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:46:08.422773Z",
     "start_time": "2024-06-30T13:46:08.407212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the features and the target\n",
    "X  = df_main[['year', 'month', 'mean_air_temp_mean', 'durchsch_aufenthaltsdauer_tage', 'urlaubs_campingplaetze_offen', 'urlaubs_stellplaetze_offen', 'mean_drought_index', 'mean_evapo_p', 'mean_evapo_r', 'mean_frost_depth', 'mean_precipitation', 'mean_soil_moist', 'mean_soil_temperature_5cm', 'mean_sunshine_duration', 'land_Baden-Württemberg', 'land_Bayern', 'land_Berlin', 'land_Brandenburg', 'land_Bremen', 'land_Hamburg', 'land_Hessen', 'land_Mecklenburg-Vorpommern', 'land_Niedersachsen', 'land_Nordrhein-Westfalen', 'land_Rheinland-Pfalz', 'land_Saarland', 'land_Sachsen', 'land_Sachsen-Anhalt', 'land_Schleswig-Holstein', 'land_Thüringen']]\n",
    "y = df_main['uebernachtungen_anzahl']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "fb5b80fa114cfe38",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:47:37.821130Z",
     "start_time": "2024-06-30T13:47:37.808580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "523d9df23a7e9e35",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T14:12:37.998802Z",
     "start_time": "2024-06-30T14:10:53.373084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a dictionary of models with hyperparameter grids\n",
    "models = {\n",
    "    \"GradientBoosting\": (HistGradientBoostingRegressor(), {\n",
    "        'learning_rate': [0.01],\n",
    "        'max_iter': [100, 1000, 10000],\n",
    "        'max_depth': [5]\n",
    "    })}\n",
    "\n",
    "# Function to perform grid search and evaluate model\n",
    "def evaluate_model(model_name, model, param_grid, X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    # Extract feature importance if available\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = best_model.feature_importances_\n",
    "    else:\n",
    "        feature_importance = None\n",
    "    return model_name, mse, mae, rmse, grid_search.best_params_, feature_importance\n",
    "\n",
    "# Run grid search and evaluation in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_model)(model_name, model, param_grid, X_train_scaled, y_train, X_test_scaled, y_test) for model_name, (model, param_grid) in models.items())\n",
    "\n",
    "# Extract and store results\n",
    "model_names, mse_results, mae_results, rmse_results, best_params, feature_importances = zip(*results)\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'MSE': mse_results,\n",
    "    'MAE': mae_results,\n",
    "    'RMSE': rmse_results,\n",
    "    'Best Parameters': best_params,\n",
    "    'Feature Importances': feature_importances\n",
    "}).sort_values('RMSE')\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n",
    "\n",
    "# Debugging: print feature importances\n",
    "for model_name, feature_importance in zip(model_names, feature_importances):\n",
    "    if feature_importance is not None:\n",
    "        print(f\"Feature importances for {model_name}: {feature_importance}\")\n",
    "    else:\n",
    "        print(f\"No feature importances for {model_name}\")\n",
    "\n",
    "# Plotting feature importance for models that provide it using Plotly\n",
    "for model_name, feature_importance in zip(model_names, feature_importances):\n",
    "    if feature_importance is not None:\n",
    "        fig = px.bar(\n",
    "            x=feature_importance,\n",
    "            y=X_train_scaled.columns,\n",
    "            orientation='h',\n",
    "            labels={'x': 'Feature Importance', 'y': 'Feature'},\n",
    "            title=f'Feature Importance for {model_name}'\n",
    "        )\n",
    "        fig.show()\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model           MSE           MAE          RMSE  \\\n",
      "0  GradientBoosting  3.663793e+09  31597.624711  60529.273857   \n",
      "\n",
      "                                     Best Parameters Feature Importances  \n",
      "0  {'learning_rate': 0.01, 'max_depth': 5, 'max_i...                None  \n",
      "No feature importances for GradientBoosting\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e065e28f3c38bf9e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
