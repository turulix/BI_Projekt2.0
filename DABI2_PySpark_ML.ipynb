{"cells":[{"cell_type":"markdown","id":"303799a4","metadata":{},"source":["# Datenvorbereitung"]},{"cell_type":"code","execution_count":1,"id":"be25cab1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/07/01 12:23:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","                                                                                \r"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.sql.functions import col\n","from pyspark.sql.types import IntegerType, FloatType, DateType\n","\n","# SparkSession ist bereits in deinem Jupyter Notebook initialisiert\n","df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"gs://dscb420_bucket/data4SuperDuperTableOfDoomV2.csv\")\n","\n","# Umwandlung der Spalten in entsprechende numerische Typen\n","df = df.withColumn(\"date\", col(\"date\").cast(DateType())) \\\n","       .withColumn(\"ankuenfte_anzahl\", col(\"ankuenfte_anzahl\").cast(IntegerType())) \\\n","       .withColumn(\"uebernachtungen_anzahl\", col(\"uebernachtungen_anzahl\").cast(IntegerType())) \\\n","       .withColumn(\"campingplaetze_anzahl\", col(\"campingplaetze_anzahl\").cast(IntegerType())) \\\n","       .withColumn(\"urlaubs_campingplaetze_anzahl\", col(\"urlaubs_campingplaetze_anzahl\").cast(IntegerType())) \\\n","       .withColumn(\"urlaubs_campingplaetze_offen\", col(\"urlaubs_campingplaetze_offen\").cast(IntegerType())) \\\n","       .withColumn(\"urlaubs_stellplaetze_anzahl\", col(\"urlaubs_stellplaetze_anzahl\").cast(IntegerType())) \\\n","       .withColumn(\"urlaubs_stellplaetze_offen\", col(\"urlaubs_stellplaetze_offen\").cast(IntegerType()))\n","\n","# Konvertierung von Float-Spalten\n","float_columns = [\n","    'ankuenfte_veraenderung_zum_vorjahreszeitraum_prozent',\n","    'uebernachtungen_veraenderung_zum_vorjahreszeitraum_prozent',\n","    'durchsch_aufenthaltsdauer_tage',\n","    'change_urlaubs_stellplaetze_offen_vorjahresmonat',\n","    'anteil_urlaubs_stellplaetze_offen_an_urlaubs_stellplaetze_anzah',\n","    'mean_air_temp_max', 'mean_air_temp_mean', 'mean_air_temp_min', \n","    'mean_drought_index', 'mean_evapo_p', 'mean_evapo_r', 'mean_frost_depth', \n","    'mean_precipitation', 'mean_soil_moist', 'mean_soil_temperature_5cm', \n","    'mean_sunshine_duration', 'std_air_temp_max', 'std_air_temp_mean', \n","    'std_air_temp_min', 'std_drought_index', 'std_evapo_p', 'std_evapo_r', \n","    'std_frost_depth', 'std_precipitation', 'std_soil_moist', \n","    'std_soil_temperature_5cm', 'std_sunshine_duration'\n","]\n","\n","for column in float_columns:\n","    df = df.withColumn(column, col(column).cast(FloatType()))\n","\n","# Entfernen aller Zeilen mit Nullwerten\n","cleaned_df = df.na.drop()\n","\n","# One-Hot-Encoding f端r \"land\"\n","indexer = StringIndexer(inputCol=\"land\", outputCol=\"land_indexed\")\n","encoded_df = indexer.fit(cleaned_df).transform(cleaned_df)\n","encoder = OneHotEncoder(inputCols=[\"land_indexed\"], outputCols=[\"land_encoded\"])\n","encoded_df = encoder.fit(encoded_df).transform(encoded_df)\n","\n","# Auswahl der numerischen Features und der kategorialen Features nach Encoding\n","numeric_features = ['durchsch_aufenthaltsdauer_tage', 'mean_air_temp_mean', 'mean_drought_index',\n","                    'mean_evapo_p', 'mean_evapo_r', 'mean_frost_depth', 'mean_precipitation', \n","                    'mean_soil_moist', 'mean_soil_temperature_5cm', 'mean_sunshine_duration',\n","                    'urlaubs_campingplaetze_offen', 'urlaubs_stellplaetze_offen']\n","\n","# Assembler f端r alle Features inklusive der one-hot-kodierten\n","assembler = VectorAssembler(inputCols=numeric_features + [\"land_encoded\"], outputCol=\"assembled_features\")\n","assembled_df = assembler.transform(encoded_df)\n","\n","# Anwenden des StandardScalers\n","scaler = StandardScaler(inputCol=\"assembled_features\", outputCol=\"features\", withStd=True, withMean=True)\n","scaled_df = scaler.fit(assembled_df).transform(assembled_df)\n","\n","train_data, test_data = scaled_df.randomSplit([0.8, 0.2], seed=42)"]},{"cell_type":"markdown","id":"49d0461e","metadata":{},"source":["# Simples Lineares Regressionsmodell"]},{"cell_type":"code","execution_count":2,"id":"08fa38b8","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 9:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+----------------+------------------+\n","|            features|ankuenfte_anzahl|        prediction|\n","+--------------------+----------------+------------------+\n","|[0.10171832282235...|           14672|51107.526405051845|\n","|[0.58646406012829...|          193660| 133934.6176779811|\n","|[0.82883712140194...|           29347|  68618.9428446633|\n","|[0.58646406012829...|           10284| 41081.70389784705|\n","|[0.66725495213905...|           60341| 88552.97596692781|\n","|[1.15200107468636...|            4698|10611.749021976808|\n","|[-0.2214456304620...|          171536|122275.72334380273|\n","|[1.63674681199230...|            4858|26680.280190481313|\n","|[1.31358285870788...|            5176|25466.336978484505|\n","|[0.50567316811753...|            4471|15701.574214047487|\n","|[0.58646406012829...|            6451| 22609.25398642103|\n","|[0.02092743081159...|           61950| 97709.79456093952|\n","|[-0.1406545458306...|          186413|145173.43209580128|\n","|[1.23279196669712...|            7203| 49520.99815885831|\n","|[0.02092743081159...|          103815|127838.00489562165|\n","|[1.55595591998153...|            5961|14460.449326067235|\n","|[0.26330029946456...|            8402|39191.759291853996|\n","|[0.26330029946456...|           47588| 77833.46230560294|\n","|[0.10171832282235...|           54767|  86777.7336119231|\n","|[1.31358285870788...|            4733| 58545.08963105183|\n","+--------------------+----------------+------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Training des linearen Regressionsmodells\n","lr = LinearRegression(featuresCol=\"features\", labelCol=\"ankuenfte_anzahl\", regParam=0.1)\n","model = lr.fit(train_data)\n","predictions = model.transform(test_data)\n","\n","# Vorhersagen und Bewertung\n","predictions.select(\"features\", \"ankuenfte_anzahl\", \"prediction\").show()"]},{"cell_type":"code","execution_count":3,"id":"08753fce","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 10:>                                                         (0 + 1) / 1]\r","\r","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Root Mean Squared Error (RMSE) auf Testdaten = 41450.33198538461\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 11:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["R2 auf Testdaten = 0.5934726998951146\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","# Evaluation des Modells\n","evaluator = RegressionEvaluator(labelCol=\"ankuenfte_anzahl\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = evaluator.evaluate(predictions)\n","print(f\"Root Mean Squared Error (RMSE) auf Testdaten = {rmse}\")\n","\n","r2_evaluator = RegressionEvaluator(labelCol=\"ankuenfte_anzahl\", predictionCol=\"prediction\", metricName=\"r2\")\n","r2 = r2_evaluator.evaluate(predictions)\n","print(f\"R2 auf Testdaten = {r2}\")"]},{"cell_type":"markdown","id":"dd2f60fe","metadata":{},"source":["# Random Forest"]},{"cell_type":"code","execution_count":null,"id":"51617ed3","metadata":{},"outputs":[],"source":["from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n","from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# Beispiel mit Random Forest\n","rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"ankuenfte_anzahl\")\n","\n","# Erstelle das Parametergitter\n","rf_paramGrid = ParamGridBuilder() \\\n","    .addGrid(rf.numTrees, [10, 20]) \\\n","    .addGrid(rf.maxDepth, [5, 7]) \\\n","    .build()\n","\n","# Evaluator\n","evaluator = RegressionEvaluator(labelCol=\"ankuenfte_anzahl\", predictionCol=\"prediction\", metricName=\"rmse\")\n","\n","# Konfiguriere den TrainValidationSplit\n","rf_tvs = TrainValidationSplit(estimator=rf,\n","                              estimatorParamMaps=rf_paramGrid,\n","                              evaluator=evaluator,\n","                              trainRatio=0.8)  # 80% der Daten f端r Training, 20% f端r Validierung\n","\n","# Trainiere das Modell\n","rf_tvsModel = rf_tvs.fit(train_data)\n","best_rf_model = rf_tvsModel.bestModel\n","\n","# Vorhersagen treffen und Modell bewerten\n","rf_predictions = best_rf_model.transform(test_data)\n","rf_best_rmse = evaluator.evaluate(rf_predictions)\n","print(f\"Best Random Forest RMSE: {rf_best_rmse}\")\n","\n","# Optional: Ausgabe weiterer Metriken wie R2\n","rf_r2 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"r2\"})\n","print(f\"Random Forest R2: {gbt_r2}\")"]},{"cell_type":"markdown","id":"d8d338bb","metadata":{},"source":["# Gradient Boosted Trees"]},{"cell_type":"code","execution_count":null,"id":"189a5105","metadata":{},"outputs":[],"source":["# Beispiel mit Gradient Boosting Trees\n","gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"ankuenfte_anzahl\")\n","gbt_paramGrid = ParamGridBuilder() \\\n","    .addGrid(gbt.maxIter, [10, 20, 50]) \\\n","    .addGrid(gbt.maxDepth, [5, 10, 20]) \\\n","    .build()\n","\n","gbt_tvs = TrainValidationSplit(estimator=gbt,\n","                               estimatorParamMaps=gbt_paramGrid,\n","                               evaluator=evaluator,\n","                               trainRatio=0.8)\n","\n","# Trainiere das Modell\n","gbt_tvsModel = gbt_tvs.fit(train_data)\n","best_gbt_model = gbt_tvsModel.bestModel\n","\n","# Vorhersagen treffen und Modell bewerten\n","gbt_predictions = best_gbt_model.transform(test_data)\n","gbt_best_rmse = evaluator.evaluate(gbt_predictions)\n","print(f\"Best Gradient Boosted Trees RMSE: {gbt_best_rmse}\")"]},{"cell_type":"markdown","id":"afc7497f","metadata":{},"source":["# Bei Bedarf: Manuell nochmal beste Modelle trainieren:"]},{"cell_type":"code","execution_count":4,"id":"2e794dce","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: An illegal reflective access operation has occurred                    \n","WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.5.0.jar) to field java.nio.charset.Charset.name\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Gradient Boosted Trees RMSE: 23061.83834447464\n","Gradient Boosted Trees R2: 0.8741591809480382\n"]}],"source":["from pyspark.ml.regression import GBTRegressor\n","# Gradient Boosting Trees Regressor\n","gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"ankuenfte_anzahl\", maxIter=50, maxDepth=5)\n","\n","# Trainieren des Gradient Boosting Trees Modells\n","gbt_model = gbt.fit(train_data)\n","\n","# Vorhersagen treffen\n","gbt_predictions = gbt_model.transform(test_data)\n","\n","# Evaluation\n","gbt_evaluator = RegressionEvaluator(labelCol=\"ankuenfte_anzahl\", predictionCol=\"prediction\", metricName=\"rmse\")\n","gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)\n","print(f\"Gradient Boosted Trees RMSE: {gbt_rmse}\")\n","\n","# Optional: Ausgabe weiterer Metriken wie R2\n","gbt_r2 = gbt_evaluator.evaluate(gbt_predictions, {gbt_evaluator.metricName: \"r2\"})\n","print(f\"Gradient Boosted Trees R2: {gbt_r2}\")\n"]},{"cell_type":"code","execution_count":5,"id":"d6658272","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest RMSE: 35138.448729572905\n","Random Forest R2: 0.7078547305490359\n"]}],"source":["from pyspark.ml.regression import RandomForestRegressor\n","# Random Forest Regressor\n","rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"ankuenfte_anzahl\")\n","\n","# Trainieren des Random Forest Modells\n","rf_model = rf.fit(train_data)\n","\n","# Vorhersagen treffen\n","rf_predictions = rf_model.transform(test_data)\n","\n","# Evaluation\n","rf_evaluator = RegressionEvaluator(labelCol=\"ankuenfte_anzahl\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rf_rmse = rf_evaluator.evaluate(rf_predictions)\n","print(f\"Random Forest RMSE: {rf_rmse}\")\n","\n","# Optional: Ausgabe weiterer Metriken wie R2\n","rf_r2 = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"r2\"})\n","print(f\"Random Forest R2: {rf_r2}\")\n"]},{"cell_type":"markdown","id":"b6ae4982","metadata":{},"source":["# Modelle in das Bucket speichern"]},{"cell_type":"code","execution_count":7,"id":"e83760c1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["model_path = \"gs://dscb420_bucket/lr_model\"\n","\n","model.write().overwrite().save(model_path)"]},{"cell_type":"code","execution_count":8,"id":"93b3319b","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["rf_model_path = \"gs://dscb420_bucket/rf_model\"\n","\n","# Modell im GCS Bucket speichern\n","rf_model.write().overwrite().save(rf_model_path)"]},{"cell_type":"code","execution_count":9,"id":"5d72deac","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["gbt_model_path = \"gs://dscb420_bucket/gbt_model\"\n","\n","gbt_model.write().overwrite().save(gbt_model_path)"]},{"cell_type":"code","execution_count":null,"id":"55147fe4","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}